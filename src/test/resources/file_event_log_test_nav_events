{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1466087847334,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"spark.job.interruptOnCancel":"false","spark.job.description":"myJobDescription","spark.jobGroup.id":"myJobGroup"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Accumulables":[]},"Properties":{"spark.job.interruptOnCancel":"false","spark.job.description":"myJobDescription","spark.jobGroup.id":"myJobGroup"}}
{"Event":"SparkListenerTaskStart","Stage ID":0,"Stage Attempt ID":0,"Task Info":{"Task ID":0,"Index":5,"Attempt":0,"Launch Time":1466087848562,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":0,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":1,"Index":24,"Attempt":0,"Launch Time":1466087848577,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1466087852118,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"worker194.datacenter","Executor Deserialize Time":1192,"Executor Run Time":2301,"Result Size":2673,"JVM GC Time":76,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134283264,"Records Read":52818},"Updated Blocks":[{"Block ID":"rdd_1_24","Status":{"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Memory Size":269121136,"ExternalBlockStore Size":0,"Disk Size":0}}]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":68,"Memory Size":17385843040,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Submission Time":1466087848557,"Completion Time":1466087938686,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1466087938689,"Job Result":{"Result":"JobSucceeded"}}
{"Event":"SparkListenerJobStart","Job ID":0,"Submission Time":1466087847334,"Stage Infos":[{"Stage ID":0,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Accumulables":[]}],"Stage IDs":[0],"Properties":{"spark.job.interruptOnCancel":"false","spark.job.description":"myJobDescription","spark.jobGroup.id":"myJobGroup"}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Accumulables":[]},"Properties":{"spark.job.interruptOnCancel":"false","spark.job.description":"myJobDescription","spark.jobGroup.id":"myJobGroup"}}
{"Event":"SparkListenerTaskStart","Stage ID":1,"Stage Attempt ID":0,"Task Info":{"Task ID":2,"Index":5,"Attempt":0,"Launch Time":1466087848562,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":1,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":2,"Index":24,"Attempt":0,"Launch Time":1466087848577,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1466087852118,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"worker194.datacenter","Executor Deserialize Time":1192,"Executor Run Time":2301,"Result Size":2673,"JVM GC Time":76,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134283264,"Records Read":52818},"Updated Blocks":[{"Block ID":"rdd_1_24","Status":{"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Memory Size":269121136,"ExternalBlockStore Size":0,"Disk Size":0}}]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":1,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":68,"Memory Size":17385843040,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Submission Time":1466087848557,"Completion Time":1466087938686,"Accumulables":[]}}
{"Event":"SparkListenerStageSubmitted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Accumulables":[]},"Properties":{"spark.job.interruptOnCancel":"false","spark.job.description":"myJobDescription","spark.jobGroup.id":"myJobGroup"}}
{"Event":"SparkListenerTaskStart","Stage ID":2,"Stage Attempt ID":0,"Task Info":{"Task ID":3,"Index":5,"Attempt":0,"Launch Time":1466087848562,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":0,"Failed":false,"Accumulables":[]}}
{"Event":"SparkListenerTaskEnd","Stage ID":2,"Stage Attempt ID":0,"Task Type":"ResultTask","Task End Reason":{"Reason":"Success"},"Task Info":{"Task ID":3,"Index":24,"Attempt":0,"Launch Time":1466087848577,"Executor ID":"2","Host":"worker194.datacenter","Locality":"NODE_LOCAL","Speculative":false,"Getting Result Time":0,"Finish Time":1466087852118,"Failed":false,"Accumulables":[]},"Task Metrics":{"Host Name":"worker194.datacenter","Executor Deserialize Time":1192,"Executor Run Time":2301,"Result Size":2673,"JVM GC Time":76,"Result Serialization Time":0,"Memory Bytes Spilled":0,"Disk Bytes Spilled":0,"Input Metrics":{"Data Read Method":"Hadoop","Bytes Read":134283264,"Records Read":52818},"Updated Blocks":[{"Block ID":"rdd_1_24","Status":{"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Memory Size":269121136,"ExternalBlockStore Size":0,"Disk Size":0}}]}}
{"Event":"SparkListenerStageCompleted","Stage Info":{"Stage ID":2,"Stage Attempt ID":0,"Stage Name":"count at <console>:22","Number of Tasks":68,"RDD Info":[{"RDD ID":1,"Name":"My RDD Name","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[0],"Storage Level":{"Use Disk":false,"Use Memory":true,"Use ExternalBlockStore":false,"Deserialized":true,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":68,"Memory Size":17385843040,"ExternalBlockStore Size":0,"Disk Size":0},{"RDD ID":0,"Name":"/my/dataset","Scope":"{\"id\":\"0\",\"name\":\"textFile\"}","Parent IDs":[],"Storage Level":{"Use Disk":false,"Use Memory":false,"Use ExternalBlockStore":false,"Deserialized":false,"Replication":1},"Number of Partitions":68,"Number of Cached Partitions":0,"Memory Size":0,"ExternalBlockStore Size":0,"Disk Size":0}],"Parent IDs":[],"Details":"org.apache.spark.rdd.RDD.count(RDD.scala:1125)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:22)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:27)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:29)\n$line26.$read$$iwC$$iwC$$iwC$$iwC$$iwC.<init>(<console>:31)\n$line26.$read$$iwC$$iwC$$iwC$$iwC.<init>(<console>:33)\n$line26.$read$$iwC$$iwC$$iwC.<init>(<console>:35)\n$line26.$read$$iwC$$iwC.<init>(<console>:37)\n$line26.$read$$iwC.<init>(<console>:39)\n$line26.$read.<init>(<console>:41)\n$line26.$read$.<init>(<console>:45)\n$line26.$read$.<clinit>(<console>)\n$line26.$eval$.<init>(<console>:7)\n$line26.$eval$.<clinit>(<console>)\n$line26.$eval.$print(<console>)\nsun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)\nsun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)\nsun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)\njava.lang.reflect.Method.invoke(Method.java:497)\norg.apache.spark.repl.SparkIMain$ReadEvalPrint.call(SparkIMain.scala:1065)","Submission Time":1466087848557,"Completion Time":1466087938686,"Accumulables":[]}}
{"Event":"SparkListenerJobEnd","Job ID":0,"Completion Time":1466087938689,"Job Result":{"Result":"JobSucceeded"}}